import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import git
from datetime import datetime
import re
import logging
from matplotlib.dates import DateFormatter
from config_shared import PRIX_MOYEN_PAR_COLLECTION, SEUIL_BONNE_AFFAIRE, SEUIL_TRES_BONNE_AFFAIRE

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- CONFIGURATION ---
FICHIER_PRIX = "prix_lego.xlsx"
FICHIER_CONFIG = "config_sets.xlsx"
WIKI_REPO_URL = os.getenv("WIKI_URL", "https://github.com/Aktawind/lego-price-tracker.wiki.git")
WIKI_LOCAL_PATH = "lego_wiki"

# --- Nettoyage du dossier wiki ---
def nettoyer_dossier_wiki(chemin_dossier):
    """Supprime tous les fichiers .md et les images de graphiques existants."""
    logging.info(f"Nettoyage du dossier du wiki : {chemin_dossier}")
    # Nettoyer les fichiers .md √† la racine
    for fichier in os.listdir(chemin_dossier):
        if fichier.endswith(".md"):
            os.remove(os.path.join(chemin_dossier, fichier))
    
    # Nettoyer les graphiques dans le dossier images
    dossier_images = os.path.join(chemin_dossier, "images")
    if os.path.exists(dossier_images):
        for fichier in os.listdir(dossier_images):
            if fichier.startswith("graph_") and fichier.endswith(".png"):
                os.remove(os.path.join(dossier_images, fichier))

# --- Pr√©paration du chemin local pour le d√©p√¥t wiki ---
def preparer_repo_wiki():
    """Clone le repo du wiki s'il n'existe pas, ou le met √† jour."""
    if os.path.exists(WIKI_LOCAL_PATH):
        logging.info("Mise √† jour du d√©p√¥t wiki local...")
        repo = git.Repo(WIKI_LOCAL_PATH)
        repo.remotes.origin.pull()
    else:
        logging.info("Clonage du d√©p√¥t wiki...")
        git.Repo.clone_from(WIKI_REPO_URL, WIKI_LOCAL_PATH)
    
    # Cr√©er le dossier pour les images s'il n'existe pas
    os.makedirs(os.path.join(WIKI_LOCAL_PATH, "images"), exist_ok=True)

# --- G√âN√âRATION DES GRAPHIQUES ---
def generer_graphique(df_set_history, id_set):
    """G√©n√®re et sauvegarde un graphique d'√©volution des prix pour un set."""
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(10, 6))

    # Utiliser Seaborn pour un joli graphique
    sns.lineplot(data=df_set_history, x='Date', y='Prix', hue='Site', marker='o', ax=ax)

    unique_dates = df_set_history['Date'].unique()
    ax.set_xticks(unique_dates)
    date_format = DateFormatter("%d/%m/%Y")
    ax.xaxis.set_major_formatter(date_format)

    ax.set_title(f"√âvolution du prix pour le set {id_set}", fontsize=16)
    ax.set_ylabel("Prix (‚Ç¨)")
    ax.set_xlabel("Date")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    
    chemin_image = os.path.join(WIKI_LOCAL_PATH, "images", f"graph_{id_set}.png")
    plt.savefig(chemin_image, dpi=150)
    plt.close(fig) # Fermer la figure pour lib√©rer la m√©moire
    logging.info(f"Graphique g√©n√©r√© : {chemin_image}")
    return f"images/graph_{id_set}.png"

# --- G√âN√âRATION DES PAGES WIKI ---
# REMPLACEZ VOTRE FONCTION generer_pages_wiki PAR CELLE-CI

# Dans generer_wiki.py

def generer_pages_wiki(df_config):
    logging.info("D√©but de la g√©n√©ration des pages du Wiki...")
    
    try:
        # On s'assure de lire la colonne URL comme du texte
        df_prix = pd.read_excel(FICHIER_PRIX, dtype={'ID_Set': str, 'URL': str})
        df_prix['Date'] = pd.to_datetime(df_prix['Date']).dt.normalize()
    except FileNotFoundError as e:
        logging.error(f"Erreur: Fichier d'historique '{FICHIER_PRIX}' manquant - {e}")
        return
    except KeyError:
        # G√®re le cas o√π l'ancien fichier Excel n'a pas encore la colonne URL
        logging.warning("Colonne 'URL' non trouv√©e dans l'historique. Les liens ne seront pas g√©n√©r√©s pour cette passe.")
        df_prix = pd.read_excel(FICHIER_PRIX, dtype={'ID_Set': str})
        df_prix['Date'] = pd.to_datetime(df_prix['Date']).dt.normalize()
        df_prix['URL'] = '' # On ajoute une colonne URL vide pour la compatibilit√©

    preparer_repo_wiki()
    nettoyer_dossier_wiki(WIKI_LOCAL_PATH)

    home_content = ["# Suivi des Prix LEGO", "Mis √† jour le : " + datetime.now().strftime('%d/%m/%Y √† %H:%M') + "\n",
                    "| Image | Set | Meilleur Prix Actuel |", "|:---:|:---|:---|"]
    
    for index, config_set in df_config.iterrows():
        id_set = config_set['ID_Set']
        nom_set = config_set['Nom_Set']
        image_url = config_set.get('Image_URL', '')
        nb_pieces = pd.to_numeric(config_set.get('nbPieces'), errors='coerce')
        collection = config_set.get('Collection', 'default')

        # On prend TOUT l'historique pour ce set, sans filtrer les sites
        df_set_history = df_prix[df_prix['ID_Set'] == id_set].copy()
        
        if df_set_history.empty:
            logging.warning(f"Aucun historique de prix trouv√© pour le set {id_set}. Il sera ignor√© pour le wiki.")
            continue

        dernier_scan = df_set_history.sort_values('Date').groupby('Site').last().reset_index()
        dernier_scan_trie = dernier_scan.sort_values('Prix', ascending=True)

        meilleur_prix_actuel = dernier_scan_trie['Prix'].min()
        site_meilleur_prix = dernier_scan_trie.iloc[0]['Site']

        # Calculs pour l'analyse de prix
        prix_moyen_collection = PRIX_MOYEN_PAR_COLLECTION.get(collection, PRIX_MOYEN_PAR_COLLECTION['default'])
        prix_juste = nb_pieces * prix_moyen_collection if pd.notna(nb_pieces) else None
        seuil_bonne = prix_juste * SEUIL_BONNE_AFFAIRE if prix_juste else None
        seuil_tres_bonne = prix_juste * SEUIL_TRES_BONNE_AFFAIRE if prix_juste else None
        
        # Nettoyage pour √©viter que les ":" cassent les liens Wiki
        nom_pour_url = nom_set.replace(':', '').replace(' ', '-')
        nom_fichier_page = f"{id_set}-{nom_pour_url}.md"
        lien_wiki = f"{id_set}-{nom_pour_url}"

        # --- Page d'accueil ---
        indicateur_deal = ""
        if seuil_tres_bonne and meilleur_prix_actuel <= seuil_tres_bonne:
            indicateur_deal = "üî•üî•"
        elif seuil_bonne and meilleur_prix_actuel <= seuil_bonne:
            indicateur_deal = "‚úÖ‚úÖ"

        image_md = f"[<img src='{image_url}' width='100'>]({lien_wiki})" if image_url else ""
        set_md = f"**[{nom_set}]({lien_wiki})**<br>*{id_set}*"
        prix_md = f"**{meilleur_prix_actuel:.2f}‚Ç¨** {indicateur_deal}<br>*sur {site_meilleur_prix}*"
        home_content.append(f"| {image_md} | {set_md} | {prix_md} |")

        # --- Pages de d√©tail ---
        page_detail_content = [f"# {nom_set} ({id_set})"]
        if image_url: page_detail_content.append(f"<img src='{image_url}' alt='Image de {nom_set}' width='400'>\n")
        
        if prix_juste:
            prix_plus_bas_jamais_vu = df_set_history['Prix'].min()
            page_detail_content.append("## Analyse du Prix")
            page_detail_content.append(f"- **Collection :** {collection}")
            page_detail_content.append(f"- **Nombre de pi√®ces :** {int(nb_pieces)}")
            page_detail_content.append(f"- **Prix juste estim√© :** {prix_juste:.2f}‚Ç¨ ({prix_moyen_collection:.3f}‚Ç¨/pi√®ce)")
            page_detail_content.append(f"- **Seuil Bonne Affaire :** < {seuil_bonne:.2f}‚Ç¨")
            page_detail_content.append(f"- **Seuil TR√àS Bonne Affaire :** < {seuil_tres_bonne:.2f}‚Ç¨")
            page_detail_content.append(f"- **Prix le plus bas enregistr√© :** {prix_plus_bas_jamais_vu:.2f}‚Ç¨\n")

        page_detail_content.append("## Prix Actuels par Site")
        page_detail_content.append("| Site | Prix Actuel | Prix par Pi√®ce | Analyse |")
        page_detail_content.append("|:---|:---:|:---:|:---:|")

        # On boucle sur le tableau tri√© des prix trouv√©s
        for _, row in dernier_scan_trie.iterrows():
            prix = row['Prix']
            site = row['Site']
            
            # === LOGIQUE DE LIENS CONDITIONNELS ===
            colonne_url_config = f"URL_{site.replace('.', '_')}"
            url_manuelle = config_set.get(colonne_url_config)

            if pd.notna(url_manuelle) and url_manuelle:
                site_md = f"[{site}]({url_manuelle})"
            else:
                site_md = site
            # ======================================
            
            analyse_emoji = "-"
            if prix_juste:
                ppp_actuel = prix / nb_pieces
                if ppp_actuel <= prix_moyen_collection * SEUIL_TRES_BONNE_AFFAIRE: analyse_emoji = "TR√àS Bonne Affaire üî•üî•"
                elif ppp_actuel <= prix_moyen_collection * SEUIL_BONNE_AFFAIRE: analyse_emoji = "Bonne Affaire ‚úÖ‚úÖ"
                elif ppp_actuel <= prix_moyen_collection: analyse_emoji = "Prix Juste ‚úÖ"
                else: analyse_emoji = "√âlev√© ‚ùå"
                page_detail_content.append(f"| {site_md} | **{prix:.2f}‚Ç¨** | {ppp_actuel:.3f}‚Ç¨ | {analyse_emoji} |")
            else:
                page_detail_content.append(f"| {site_md} | **{prix:.2f}‚Ç¨** | - | {analyse_emoji} |")

        chemin_graphique = generer_graphique(df_set_history, id_set)
        page_detail_content.append("\n## √âvolution des prix")
        page_detail_content.append(f"<img src='./{chemin_graphique}' alt='Graphique des prix' width='900'>\n")
        
        with open(os.path.join(WIKI_LOCAL_PATH, nom_fichier_page), 'w', encoding='utf-8') as f:
            f.write("\n".join(page_detail_content))
        logging.info(f"Page de d√©tail g√©n√©r√©e : {nom_fichier_page}")

    with open(os.path.join(WIKI_LOCAL_PATH, "Home.md"), 'w', encoding='utf-8') as f:
        f.write("\n".join(home_content))
    logging.info("Page d'accueil 'Home.md' g√©n√©r√©e.")

# --- PUSH DES CHANGEMENTS VERS LE WIKI ---
def pousser_changements_wiki():
    try:
        repo = git.Repo(WIKI_LOCAL_PATH)
        if not repo.is_dirty(untracked_files=True):
            logging.info("Aucun changement √† pousser sur le wiki.")
            return

        logging.info("D√©tection de changements. Configuration de Git et push vers le wiki...")
        
        # Configuration de l'utilisateur Git DANS le script
        repo.config_writer().set_value("user", "name", os.getenv("GIT_USER", "Bot")).release()
        repo.config_writer().set_value("user", "email", os.getenv("GIT_EMAIL", "bot@example.com")).release()
        
        repo.git.add(A=True)
        repo.index.commit(f"Mise √† jour automatique des prix - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        
        # On s'assure que l'URL distante est la bonne (celle avec le token)
        origin = repo.remote(name='origin')
        origin.set_url(WIKI_REPO_URL)
        
        origin.push()
        logging.info("Wiki mis √† jour avec succ√®s !")
    except Exception as e:
        logging.error(f"Erreur lors du push vers le wiki : {e}")

# --- POINT D'ENTR√âE DU SCRIPT ---
if __name__ == "__main__":
    df_config = pd.read_excel(FICHIER_CONFIG, dtype={'ID_Set': str})
    if not df_config.empty:
        generer_pages_wiki(df_config) # On passe df_config en argument
        pousser_changements_wiki()