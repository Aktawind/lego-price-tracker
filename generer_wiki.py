import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import git
from datetime import datetime
import re
import logging
from matplotlib.dates import DateFormatter
from config_shared import PRIX_MOYEN_PAR_COLLECTION, SEUIL_BONNE_AFFAIRE, SEUIL_TRES_BONNE_AFFAIRE

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- CONFIGURATION ---
FICHIER_PRIX = "prix_lego.xlsx"
FICHIER_CONFIG = "config_sets.xlsx"
WIKI_REPO_URL = os.getenv("WIKI_URL", "https://github.com/Aktawind/lego-price-tracker.wiki.git")
WIKI_LOCAL_PATH = "lego_wiki"

# --- Nettoyage du dossier wiki ---
def nettoyer_dossier_wiki(chemin_dossier):
    """Supprime tous les fichiers .md et les images de graphiques existants."""
    logging.info(f"Nettoyage du dossier du wiki : {chemin_dossier}")
    # Nettoyer les fichiers .md √† la racine
    for fichier in os.listdir(chemin_dossier):
        if fichier.endswith(".md"):
            os.remove(os.path.join(chemin_dossier, fichier))
    
    # Nettoyer les graphiques dans le dossier images
    dossier_images = os.path.join(chemin_dossier, "images")
    if os.path.exists(dossier_images):
        for fichier in os.listdir(dossier_images):
            if fichier.startswith("graph_") and fichier.endswith(".png"):
                os.remove(os.path.join(dossier_images, fichier))

# --- Pr√©paration du chemin local pour le d√©p√¥t wiki ---
def preparer_repo_wiki():
    """Clone le repo du wiki s'il n'existe pas, ou le met √† jour."""
    if os.path.exists(WIKI_LOCAL_PATH):
        logging.info("Mise √† jour du d√©p√¥t wiki local...")
        repo = git.Repo(WIKI_LOCAL_PATH)
        repo.remotes.origin.pull()
    else:
        logging.info("Clonage du d√©p√¥t wiki...")
        git.Repo.clone_from(WIKI_REPO_URL, WIKI_LOCAL_PATH)
    
    # Cr√©er le dossier pour les images s'il n'existe pas
    os.makedirs(os.path.join(WIKI_LOCAL_PATH, "images"), exist_ok=True)

# --- G√âN√âRATION DES GRAPHIQUES ---
def generer_graphique(df_set_history, id_set):
    """G√©n√®re et sauvegarde un graphique d'√©volution des prix pour un set."""
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(10, 6))

    # Utiliser Seaborn pour un joli graphique
    sns.lineplot(data=df_set_history, x='Date', y='Prix', hue='Site', marker='o', ax=ax)

    unique_dates = df_set_history['Date'].unique()
    ax.set_xticks(unique_dates)
    date_format = DateFormatter("%d/%m/%Y")
    ax.xaxis.set_major_formatter(date_format)

    ax.set_title(f"√âvolution du prix pour le set {id_set}", fontsize=16)
    ax.set_ylabel("Prix (‚Ç¨)")
    ax.set_xlabel("Date")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    
    chemin_image = os.path.join(WIKI_LOCAL_PATH, "images", f"graph_{id_set}.png")
    plt.savefig(chemin_image, dpi=150)
    plt.close(fig) # Fermer la figure pour lib√©rer la m√©moire
    logging.info(f"Graphique g√©n√©r√© : {chemin_image}")
    return f"images/graph_{id_set}.png"

# --- G√âN√âRATION DES PAGES WIKI ---
def generer_pages_wiki(df_config):
    logging.info("D√©but de la g√©n√©ration des pages du Wiki...")
    
    try:
        df_prix = pd.read_excel(FICHIER_PRIX, dtype={'ID_Set': str})
        df_config = pd.read_excel(FICHIER_CONFIG, dtype={'ID_Set': str})
        df_prix['Date'] = pd.to_datetime(df_prix['Date']).dt.normalize()
    except FileNotFoundError as e:
        logging.error(f"Erreur: Fichier manquant - {e}")
        return

    preparer_repo_wiki()
    nettoyer_dossier_wiki(WIKI_LOCAL_PATH)

    home_content = ["# Suivi des Prix LEGO", "Mis √† jour le : " + datetime.now().strftime('%d/%m/%Y √† %H:%M') + "\n",
                    "| Image | Set | Meilleur Prix Actuel |", "|:---:|:---|:---|"]
    
    for index, config_set in df_config.iterrows():
        id_set = config_set['ID_Set']
        nom_set = config_set['Nom_Set']
        image_url = config_set.get('Image_URL', '')
        nb_pieces = pd.to_numeric(config_set.get('nbPieces'), errors='coerce')
        collection = config_set.get('Collection', 'default')

        df_set_history = df_prix[df_prix['ID_Set'] == id_set].copy()
        
        if df_set_history.empty:
            logging.warning(f"Aucun historique de prix pour {id_set}. Ignor√©.")
            continue

        dernier_scan = df_set_history.sort_values('Date').groupby('Site').last().reset_index()
        meilleur_prix_actuel = dernier_scan['Prix'].min()
        site_meilleur_prix = dernier_scan.iloc[0]['Site'] # Le premier de la liste tri√©e

        # --- Calculs pour l'analyse de prix ---
        prix_moyen_collection = PRIX_MOYEN_PAR_COLLECTION.get(collection, PRIX_MOYEN_PAR_COLLECTION['default'])
        prix_juste = nb_pieces * prix_moyen_collection if pd.notna(nb_pieces) else None
        seuil_bonne = prix_juste * SEUIL_BONNE_AFFAIRE if prix_juste else None
        seuil_tres_bonne = prix_juste * SEUIL_TRES_BONNE_AFFAIRE if prix_juste else None
        
        # --- G√©n√©ration des noms de page et liens ---
        nom_fichier_page = f"{id_set}-{nom_set.replace(' ', '-')}.md"
        lien_wiki = nom_fichier_page[:-3] # On enl√®ve le .md pour le lien

        # --- Page d'accueil ---
        indicateur_deal = ""
        if seuil_tres_bonne and meilleur_prix_actuel <= seuil_tres_bonne:
            indicateur_deal = "üî•üî•üî•"
        elif seuil_bonne and meilleur_prix_actuel <= seuil_bonne:
            indicateur_deal = "‚úÖ‚úÖ"

        image_md = f"[<img src='{image_url}' width='100'>]({lien_wiki})" if image_url else ""
        set_md = f"**[{nom_set}]({lien_wiki})**<br>*{id_set}*"
        prix_md = f"**{meilleur_prix_actuel:.2f}‚Ç¨** {indicateur_deal}<br>*sur {site_meilleur_prix}*"
        home_content.append(f"| {image_md} | {set_md} | {prix_md} |")

        # --- Pages de d√©tail ---
        chemin_graphique = generer_graphique(df_set_history, id_set)
        #page_detail_content = [f"# {nom_set} ({id_set})"]
        page_detail_content = [f"<img src='{image_url}' alt='Image de {nom_set}' width='400'>\n"]
        
        # Section d'analyse
        if prix_juste:
            prix_plus_bas_jamais_vu = df_set_history['Prix'].min()
            page_detail_content.append("## Analyse du Prix")
            page_detail_content.append(f"- **Collection :** {collection}")
            page_detail_content.append(f"- **Nombre de pi√®ces :** {int(nb_pieces)}")
            page_detail_content.append(f"- **Prix juste estim√© :** {prix_juste:.0f}‚Ç¨")
            page_detail_content.append(f"- **Seuil Bonne Affaire :** < {seuil_bonne:.2f}‚Ç¨")
            page_detail_content.append(f"- **Seuil TR√àS Bonne Affaire :** < {seuil_tres_bonne:.2f}‚Ç¨")
            page_detail_content.append(f"- **Prix le plus bas enregistr√© :** {prix_plus_bas_jamais_vu:.2f}‚Ç¨\n")

            page_detail_content.append("## Prix Actuels par Site")
            page_detail_content.append("| Site | Prix Actuel | Prix par Pi√®ce | Analyse |")
            page_detail_content.append("|:---|:---:|:---:|:---:|")

            for _, row in dernier_scan.iterrows():
                prix = row['Prix']
                site = row['Site']

                colonne_url = f"URL_{site.replace('.', '_')}" # ex: Lego.com -> URL_Lego_com
                url_produit = config_set.get(colonne_url, '#')
                site_md = f"[{site}]({url_produit})"
                
                analyse_emoji = ""
                ppp_actuel = prix / nb_pieces
                
                if ppp_actuel <= prix_moyen_collection * SEUIL_TRES_BONNE_AFFAIRE:
                    analyse_emoji = "TR√àS Bonne Affaire üî•üî•üî•"
                elif ppp_actuel <= prix_moyen_collection * SEUIL_BONNE_AFFAIRE:
                    analyse_emoji = "Bonne Affaire ‚úÖ‚úÖ"
                elif ppp_actuel <= prix_moyen_collection:
                    analyse_emoji = "Prix Juste ‚úÖ"
                else:
                    analyse_emoji = "√âlev√© ‚ùå"
                
                page_detail_content.append(f"| {site_md} | **{prix:.2f}‚Ç¨** | {ppp_actuel:.3f}‚Ç¨ | {analyse_emoji} |")
        else:
             # G√©rer le cas o√π on n'a pas les infos de pi√®ces
             page_detail_content.append("\n## Prix Actuels par Site")
             page_detail_content.append("| Site | Prix Actuel |")
             page_detail_content.append("|:---|:---:|")
             for _, row in dernier_scan.iterrows():
                 page_detail_content.append(f"| {row['Site']} | **{row['Prix']:.2f}‚Ç¨** |")

        chemin_graphique = generer_graphique(df_set_history, id_set)
        page_detail_content.append("\n## √âvolution des prix")
        page_detail_content.append(f"<img src='./{chemin_graphique}' alt='Graphique des prix' width='900'>\n")
        
        with open(os.path.join(WIKI_LOCAL_PATH, nom_fichier_page), 'w', encoding='utf-8') as f:
            f.write("\n".join(page_detail_content))
        logging.info(f"Page de d√©tail g√©n√©r√©e : {nom_fichier_page}")

    with open(os.path.join(WIKI_LOCAL_PATH, "Home.md"), 'w', encoding='utf-8') as f:
        f.write("\n".join(home_content))
    logging.info("Page d'accueil 'Home.md' g√©n√©r√©e.")

# --- PUSH DES CHANGEMENTS VERS LE WIKI ---
def pousser_changements_wiki():
    try:
        repo = git.Repo(WIKI_LOCAL_PATH)
        if not repo.is_dirty(untracked_files=True):
            logging.info("Aucun changement √† pousser sur le wiki.")
            return

        logging.info("D√©tection de changements. Configuration de Git et push vers le wiki...")
        
        # Configuration de l'utilisateur Git DANS le script
        repo.config_writer().set_value("user", "name", os.getenv("GIT_USER", "Bot")).release()
        repo.config_writer().set_value("user", "email", os.getenv("GIT_EMAIL", "bot@example.com")).release()
        
        repo.git.add(A=True)
        repo.index.commit(f"Mise √† jour automatique des prix - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        
        # On s'assure que l'URL distante est la bonne (celle avec le token)
        origin = repo.remote(name='origin')
        origin.set_url(WIKI_REPO_URL)
        
        origin.push()
        logging.info("Wiki mis √† jour avec succ√®s !")
    except Exception as e:
        logging.error(f"Erreur lors du push vers le wiki : {e}")

# --- POINT D'ENTR√âE DU SCRIPT ---
if __name__ == "__main__":
    df_config = pd.read_excel(FICHIER_CONFIG, dtype={'ID_Set': str})
    if not df_config.empty:
        generer_pages_wiki(df_config) # On passe df_config en argument
        pousser_changements_wiki()